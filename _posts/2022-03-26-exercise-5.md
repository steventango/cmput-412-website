---
layout: post
title:  Exercise 5 - ML for Robotics
redirect_from:
- /exercise-5
---

## MNIST Dataset and ML basic terminologies

### Deliverable 1

<iframe
    width="100%"
    height="600"
    src="/cmput-412-website/images/exercise-5/deliverable-1-backprop.pdf"
    frameborder="0">
</iframe>

### Deliverable 2

### What data augmentation is used in training? Please delete the data augmentation and rerun the code to compare.

A random rotation of the image between (-5, 5) degrees, then add 2 pixels of
padding to the image, and then randomly cropping the image to 28 x 28 pixels.
Rerunning the code without data augmentation results in a lower test accuracy, of 97.91%
as opposed to 98.12% with data augmentation. This is because data augmentation
helps prevent overfitting by increasing the amount of variation in the training
data.

### What is the batch size in the code? Please change the batch size to 16 and 1024 and explain the variation in results.

The batch size in the code is 64. Changing the batch size to 16 results in a
slightly higher test accuracy of 98.13% as opposed to 98.12% with a batch size
of 64. Changing the batch size to 1024 results in a decreased test accuracy of
97.54%. This is because smaller batch sizes result in more stochastic gradients,
which can help the neural network escape local minima and find a better global
minimum.

### What activation function is used in the hidden layer? Please replace it with the linear activation function and see how the training output differs. Show your results before and after changing the activation function in your written report.

ReLU. Replacing it with the linear activation function results in only 87.02%
test accuracy. This is because the activation function has to be non-linear in
order to be able to learn a non-linear function. This is really evident in the
t-SNE plots below, where using the linear activation function leads to a model
that is unable to separate the classes well.

t-SNE before changing the activation function:
![t-SNE before](/cmput-412-website/images/exercise-5/t-SNE.avif)

t-SNE after changing the activation function:
![t-SNE after](/cmput-412-website/images/exercise-5/t-SNE-linear.avif)

### What is the optimization algorithm in the code? Explain the role of optimization algorithm in training process

Adam is an optimization algorithm used in the code. Adam is similar to SGD but
it computes adaptive learning rates for each parameter through exponential
moving averages of past gradients and the squared gradients. The role of the
optimization algorithm is to efficiently update the weights of the neural
network to minimize the loss function.

### Add dropout in the training and explain how the dropout layer helps in training

Adding dropout decreased the test accuracy to 97.13%, this is because
with dropout, the neural network requires more epochs to learn a good model
as some of the neurons are dropped during training and thus their weights are
not updated as much.

Dropout is a form of regularization that helps prevent overfitting by randomly
dropping neurons from the neural network during training, this forces the neural
network to learn more robust features.

## Number Detection Node

### Deliverable 3

Our strategy for detecting the numbers was to use OpenCV to extract the numbers
from the image. From the [Wikipedia page on the MNIST
database](https://en.wikipedia.org/wiki/MNIST_database), we learned that a
2-layer MLP can classify with a 1.6% error rate, thus we decided on using a
simple MLP to classify the numbers. Our model flattens the 28 x 28 pixel image
into a 784 x 1 vector, which is passed through a 800 x 1 hidden layer with
`ReLU` activation, and then a 10 x 1 output layer with `softmax` activation.

Our model architecture diagram created with
[NN-SVG](https://github.com/alexlenail/NN-SVG) is shown below:

![Model architecture](/cmput-412-website/images/exercise-5/model.avif)

We collected 87 images of the numbers by saving images from the bot like below:

![Example raw image](/cmput-412-website/images/exercise-5/test-raw.avif)

For preprocessing, we first get the blue HSV colour mask of the image to
extract the blue sticky note.
(`cv.inRange`).

![Example mask image](/cmput-412-website/images/exercise-5/test-mask1.avif)

Then, we find the contour (`cv.findContours`) of the blue sticky note.

![Example contour image](/cmput-412-website/images/exercise-5/test-contour.avif)

Then, we use OpenCV to get the convex hull of the contour (`cv.convexHull`).

![Example convex hull
image](/cmput-412-website/images/exercise-5/test-convex_hull.avif)

Then, we retrieve the corners of the convex hull using Douglas-Peucker algorithm
(`cv.approxPolyDP`) suggested by this [StackOverflow answer](https://stackoverflow.com/a/10262750).
We decided to use binary search to adjust the `epsilon`
value until we get exactly 4 corners, interestingly, we came up with the same
idea as this [StackOverflow answer](https://stackoverflow.com/a/55339684).

![Example corners image](/cmput-412-website/images/exercise-5/test-corners.avif)

Using OpenCV we calculate a perspective transform matrix to transform the
image to 28 x 28 pixels.

![Example warp image](/cmput-412-website/images/exercise-5/test-warp.avif)

We get the black HSV colour mask of the warped image (`cv.inRange`) to extract
the number.

![Example mask image](/cmput-412-website/images/exercise-5/test-mask2.avif)

To prevent noise from the warping, we set the left and right 2 px borders to 0.
Then, we normalize the image to have zero mean and unit variance.

We then trained a MLP using PyTorch on the MNIST dataset as required following
[this example](https://github.com/pytorch/examples/blob/main/mnist/main.py). We
then, fine tuned the model on our data, with a reduced initial learning rate of
0.1. Our very simple MLP gets 98% accuracy on MNIST test set. After fine
tuning on our data, our model gets 100% accuracy on our data's test set.

For inference, we apply the same preprocessing steps above, and the we use
`numpy` to load the weights and manually implement the forward pass of the
neural network with equation:

\\[ y = W_2 \max(W_1 x + b_1, 0) + b_2 = [0, 0, 0.01, 0.99, 0, 0, 0, 0, 0, 0] \\]

Then we get the digit using the `argmax` of the output of the neural
network.

\\[ p = \text{argmax} y = 3\\]

TODO: A brief paragraph discussing your results; please answer these questions:

### How well did your implemented strategy work?

TODO

### Was it reliable?

TODO

### In what situations did it perform poorly?

TODO

## Sources

- [NN-SVG](https://github.com/alexlenail/NN-SVG)
- [Wikipedia MNIST database](https://en.wikipedia.org/wiki/MNIST_database)
- [Pytorch MNIST example](https://github.com/pytorch/examples/blob/main/mnist/main.py)
- [Pytorch Data Random Split](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split)
- [OpenCV Warp Perspective](https://theailearner.com/tag/cv2-warpperspective/)
- [Stack Overflow How to force approxPolyDP() to return only the best 4 corners? - Opencv 2.4.2](https://stackoverflow.com/a/10262750)
- [OpenCV Contours and Convex Hull](https://medium.com/analytics-vidhya/contours-and-convex-hull-in-opencv-python-d7503f6651bc)
- [OpenCV Docs](https://docs.opencv.org/4.x/)
- [Stack Overflow Getting corners from convex points](https://stackoverflow.com/a/10262750)
- [Stack Overflow Image processing - I need to find the 4 corners of any quadrilater](https://stackoverflow.com/questions/38677434/image-processing-i-need-to-find-the-4-corners-of-any-quadrilater)
- [Stack Overflow Detect card MinArea Quadrilateral from contour OpenCV](https://stackoverflow.com/questions/44127342/detect-card-minarea-quadrilateral-from-contour-opencv)
